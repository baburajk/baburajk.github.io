<!DOCTYPE html>
<html lang="en">
<head>  
	<meta charset="utf-8">
	<title>Network Namespaces</title>
 
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
	<meta property="og:image" content="path/to/image.jpg">
 
<!-- build:css -->
<link rel="stylesheet" href="css/libs/bootstrap.min.css">
<link rel="stylesheet" href="css/libs/font-awesome.min.css">
<link rel="stylesheet" href="css/libs/animate.min.css">
<link rel="stylesheet" href="css/libs/slick.css">
<link rel="stylesheet" href="css/libs/magnific-popup.css">

<link rel="stylesheet" href="css/main.css">
<link rel="stylesheet" href="css/media.css">
<!-- endbuild -->
	<!-- Chrome, Firefox OS and Opera -->
	<meta name="theme-color" content="#000">
	<!-- Windows Phone -->
	<meta name="msapplication-navbutton-color" content="#000">
	<!-- iOS Safari -->
	<meta name="apple-mobile-web-app-status-bar-style" content="#000">
	<!-- <style>body { opacity:s 0; overflow-x: hidden; } html { background-color: #fff; }</style> -->
</head>
<body data-spy="scroll" data-target=".navbar" data-offset="50" class="loaded" link="blue">

	
<div class="site-content">
	<!-- Naviigation -->
	<div class="navbar-wrap">
		<div class="navbar">
			<div class="container">
				<div class="row">
					<div class="col-md-12">
						<nav class="navbar-menu">
							<div class="navbar-header">
								<button class="collapsed navbar-toggle" type="button" data-toggle="collapse" data-target=".bs-example-js-navbar-scrollspy">
									<span class="icon-bar"></span>
									<span class="icon-bar"></span>
									<span class="icon-bar"></span>
								</button>
							</div>
							 
							<div class="navbar-full">
								<div class="collapse bs-example-js-navbar-scrollspy">
									<ul class="nav navbar-nav">
										<li style="display: none;"><a></a></li>
										<li><a href="http://www.linkedin.com/in/baburajkallarakkal">About Me</a></li>
										<li><a href="http://padmavyuha.blogspot.com/">Blog</a></li>
										<li><a href="https://sourceforge.net/projects/oraclerman/">Projects</a></li>
										<li><a href="https://hub.docker.com/u/baburaj/">Docker</a></li>
										<li><a href="mailto:raj.anju@gmail.com">Contact Me</a></li>
										<li>
										</li>
									</ul>
							
								</div>
							</div>
						</nav>
					</div>
				</div>
			</div>
		</div>
	</div>
	<!-- Naviigation -->
	

<!-- Header -->
	<div class="menu-sticky"></div>
 
	<!-- Screen-one -->
	<div class="screen-one">
		<div class="container">
			<div class="row">
				<div class="col-md-12">
					<div class="screen-one-title">

						<h2> Network Namespace Internals to under Docker Interpod Communication and analysis of IPTable Rules   </h2>
					</div>
				</div>
			</div>
		</div>
	 
		<div class="container">
 
<!-- container -->		
		<div class="screen-one-item-container">
                            <h3>  </h3>
                            <img src="./imgs/namespace-v3.svg" width="800" height="800"  alt="Network Configuration">   
							<p>  </p>
							<p> </p>
 
		</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3> Simulate docker interpod communication using network namespaces. </h3>
	<p> A quick recap from the web, a network namespace is logically another copy of the network stack, with its 
         own routes, firewall rules, and network devices. 
        There are lot of nice articles explaining how the Network Namespaces works and how Docker Containerization
         makes use of the network namespaces  for inter pod communications. For the purpose of the experiment two 
         network namespaces was created on a KVM Guest VM manually to understand  the routing aspects and as well
          the IP Table rules required to enable the communication between the POD's, egress from POD to outside
           world and also  ingress to the POD's.

      
        
    </p>
	<p> </p>

<pre>

</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Default Configurations. </h3>
	<p> What does the defaults looks like before any changes were made! The default route to 192.168.122.0/24 is 
        the one for the Guest VM to communicate to the hypervisor network and 172.17.0.0/16  is the one
         defined for docker daemon. Docker daemon , corresponding routes etc. was created for all the guest VM’s 
         and for the purpose of this experiment , though I really don’t need them - decided to leave it out for 
         two reasons. a) I can use the “iptable" rules created by docker itself as a reference b) If these rules 
         by any reasons interfere that will result in more of a learning experience and go bit more deeper..
    </p>
	<p> </p>

<pre>


    [root@rhel8b ~]# ip route show
    default via 192.168.122.1 dev enp1s0 proto dhcp metric 100
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
    192.168.122.0/24 dev enp1s0 proto kernel scope link src 192.168.122.130 metric 100
    
    [root@rhel8b ~]# ip addr show
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
        inet 127.0.0.1/8 scope host lo
           valid_lft forever preferred_lft forever
        inet6 ::1/128 scope host
           valid_lft forever preferred_lft forever
    2: enp1s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000
        link/ether 52:54:00:01:1a:b3 brd ff:ff:ff:ff:ff:ff
        inet 192.168.122.130/24 brd 192.168.122.255 scope global dynamic noprefixroute enp1s0
           valid_lft 3284sec preferred_lft 3284sec
        inet6 2001:db8:ca2:3:1::37/128 scope global dynamic noprefixroute
           valid_lft 2888sec preferred_lft 2888sec
        inet6 fe80::b6c6:db5e:4ae7:956a/64 scope link noprefixroute
           valid_lft forever preferred_lft forever
    3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN group default
        link/ether 02:42:67:e9:9c:2a brd ff:ff:ff:ff:ff:ff
        inet 172.17.0.1/16 brd 172.17.255.255 scope global docker0
           valid_lft forever preferred_lft forever
    
</pre>		

</div>
<!-- container -->		



<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Namespaces and VETH Pairs </h3>
	<p> The veth pairs created would be in the root namespace by default and will not be visible on the 
        cnetns0 and cnetns1 namespaces.

        Once we have the veth pairs , move the peer end to the respective namespaces. An easy way to identify 
        the peer name is by looking at the interface ID. 

        How do we know the peer name for a veth network interface? 
        The interface ID of veth0 is “5” and the peer name for that veth is ceth0@if5 . 
        So it’s veth&lt;Interface ID&gt; == ceth0@if&lt;Interface ID&gt;
    </p>
	<p> </p>

<pre>

    [root@rhel8b netns]# ip link set dev ceth0 netns cnetns0
    [root@rhel8b netns]# ip link set dev ceth1 netns cnetns1
    
    
    [root@rhel8b netns]#  ip netns exec cnetns0 ip link show
    1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    4: ceth0@if5: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0
    
    [root@rhel8b netns]#  ip netns exec cnetns1 ip link show
    1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    6: ceth1@if7: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/ether f6:0e:f5:ee:d1:7e brd ff:ff:ff:ff:ff:ff link-netnsid 0

</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Routing and IP Address Configuration. </h3>
	<p> At this point neither of these interfaces - ceth0 or ceth1 can communicate with each other since no 
        IP addresses has been assigned, so login to each namespaces and assign the IP addresses. Since 172.16.0.0/16 is already assigned to the docker network and as I’ve not shutdown this network, decided to use a separate network space - 172.20.0.0/16  for this purpose. 

    </p>
	<p> </p>

<pre>

    [root@rhel8b netns]# nsenter --net=/var/run/netns/cnetns0 bash
    
    [root@rhel8b netns]# ip link show
    1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    4: ceth0@if5: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0

    [root@rhel8b netns]#  ip addr show
    1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    4: ceth0@if5: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0
        
    [root@rhel8b netns]# ip addr add 172.20.0.50/16 dev ceth0

    [root@rhel8b netns]# ip addr show
    1: lo: <LOOPBACK> mtu 65536 qdisc noop state DOWN group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    4: ceth0@if5: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0
        inet 172.20.0.50/16 scope global ceth0
           valid_lft forever preferred_lft forever
   
    [root@rhel8b netns]# ip route show
    
    
</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Routing and IP Address Configuration - Contd. </h3>
	<p> At this point IP address is added, but no routes has been set and this is because the physical links are down still and has not been brought up yet.

    </p>
	<p> </p>

<pre>
    [root@rhel8b netns]# ip link set ceth0 up
    [root@rhel8b netns]# ip link set lo up
    
    [root@rhel8b netns]# ip link show
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    4: ceth0@if5: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state LOWERLAYERDOWN mode DEFAULT group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0
    
    [root@rhel8b netns]# ip addr show
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
        inet 127.0.0.1/8 scope host lo
           valid_lft forever preferred_lft forever
        inet6 ::1/128 scope host
           valid_lft forever preferred_lft forever
    4: ceth0@if5: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state LOWERLAYERDOWN group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0
        inet 172.20.0.50/16 scope global ceth0
           valid_lft forever preferred_lft forever

           Note: The state of ceth0 is showing “LOWERLAYERDOWN”, though the interface itself is "<UP>" since the other end of the veth pair was only
            added and has not been brought up. Also by bringing this up the routes are also plugged into the 
            routing table which in the previous output was empty.


    [root@rhel8b netns]# ip route show
    172.20.0.0/16 dev ceth0 proto kernel scope link src 172.20.0.50 linkdown

    #Open another terminal and run similar commands on the cnetns1 to complete the configuration.

        nsenter --net=/var/run/netns/cnetns1 bash
        ip link set lo up
        ip link set ceth1 up
        ip addr add 172.20.0.60/16 dev ceth1
        ip add show


</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3> Root Namespace - VETH setup.   </h3>
	<p> The interface links on the root namespace is still down which needs to be brought up. 
    </p>
	<p> </p>

<pre>

    [root@rhel8b ~]# ip link show veth0
    5: veth0@if4: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/ether 32:e4:7c:d5:bd:8f brd ff:ff:ff:ff:ff:ff link-netns cnetns0
    
    [root@rhel8b ~]# ip link show veth1
    7: veth1@if6: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN mode DEFAULT group default qlen 1000
        link/ether ea:c9:3d:5b:64:59 brd ff:ff:ff:ff:ff:ff link-netns cnetns1 
    
    
    ip link set dev veth0 up
    ip link set dev veth1 up
    
    
    [root@rhel8b ~]# ip link show veth0
    5: veth0@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
        link/ether 32:e4:7c:d5:bd:8f brd ff:ff:ff:ff:ff:ff link-netns cnetns0
    [root@rhel8b ~]#
    [root@rhel8b ~]# ip link show veth1
    7: veth1@if6: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
        link/ether ea:c9:3d:5b:64:59 brd ff:ff:ff:ff:ff:ff link-netns cnetns1
    
    After the peer has been brought up, the interface status of ceth0 and ceth1 within the network namespaces are 
    changed from “LOWERLAYERDOWN” to  “LOWER_UP” as seen below.
    
    [root@rhel8b-cnetns0 ~ # ip link show ceth0
    4: ceth0@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0
    
    [root@rhel8b-cnetns1 ~ # ip link show ceth1
    6: ceth1@if7: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
        link/ether f6:0e:f5:ee:d1:7e brd ff:ff:ff:ff:ff:ff link-netnsid 0
    

    [root@rhel8b ~]# ip route show
    default via 192.168.122.1 dev enp1s0 proto dhcp metric 100
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
    192.168.122.0/24 dev enp1s0 proto kernel scope link src 192.168.122.130 metric 100

    [root@rhel8b ~]# ip addr add 172.20.0.5/16 dev veth0
    [root@rhel8b ~]# ip addr add 172.20.0.6/16 dev veth1

    [root@rhel8b ~]# ip route show
    default via 192.168.122.1 dev enp1s0 proto dhcp metric 100
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
    172.20.0.0/16 dev veth0 proto kernel scope link src 172.20.0.5
    172.20.0.0/16 dev veth1 proto kernel scope link src 172.20.0.6
    192.168.122.0/24 dev enp1s0 proto kernel scope link src 192.168.122.130 metric 100
 

</pre>		

</div>
<!-- container -->		



<!-- container -->		
<div class="screen-one-item-container">
	<h3> Reachability Tests. </h3>
	<p> The basic setups are done, it's about time to do the simple reachability tests. </p>
	<p> 
     
    </p>

<pre>

    # Provides the inode number associated with the process.
    [root@rhel8b ~]# lsns -o NS,PATH,USER,NETNSID | grep $(echo $$)
    4026532414 /proc/2093/ns/net root   unassigned
    
    The basic 3 use-cases that I want to test it out are as follows.
 
    a) Can one cnetns0/IP reach the IP defined on cnetns1
    b) Can any of these IP’s reach internet.
    c) Can the VM reach the IP’s defined on these NS - cnetns0/1

    #Additional notes
    Since there are two terminals/sessions opened to two different network NS, to identify the sessions, change
    the PS1 (prompt) so it's easier.

    [root@rhel8b ~]# ip netns identify $(echo $$)
    cnetns0
    
    Some additional commands for reference.
    
    # Sets the bash prompt
    export PS1="[\u@\h-$(ip netns identify $(echo $$)) \w # "


</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3> Reachability Tests - Contd. </h3>
	<p> </p>
	<p> </p>

<pre>
 

    From rootns to cnetns0 and cnetns1

    [root@rhel8b ~]# ping -c 1 172.20.0.50
    PING 172.20.0.50 (172.20.0.50) 56(84) bytes of data.
    64 bytes from 172.20.0.50: icmp_seq=1 ttl=64 time=0.055 ms
    
    --- 172.20.0.50 ping statistics ---
    1 packets transmitted, 1 received, 0% packet loss, time 0ms
    rtt min/avg/max/mdev = 0.055/0.055/0.055/0.000 ms
    
    [root@rhel8b ~]# ping -c 1 172.20.0.60
    PING 172.20.0.60 (172.20.0.60) 56(84) bytes of data.
    From 172.20.0.5 icmp_seq=1 Destination Host Unreachable
    
    --- 172.20.0.60 ping statistics ---
    1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms
    
    From cnetns0 to rootns and cnetns1
    
    [root@rhel8b-cnetns0 ~ # ping -c 1 172.20.0.5
    PING 172.20.0.5 (172.20.0.5) 56(84) bytes of data.
    64 bytes from 172.20.0.5: icmp_seq=1 ttl=64 time=0.060 ms
    
    --- 172.20.0.5 ping statistics ---
    1 packets transmitted, 1 received, 0% packet loss, time 0ms
    rtt min/avg/max/mdev = 0.060/0.060/0.060/0.000 ms
    
    [root@rhel8b-cnetns0 ~ # ping -c1 172.20.0.60
    PING 172.20.0.60 (172.20.0.60) 56(84) bytes of data.
    From 172.20.0.50 icmp_seq=1 Destination Host Unreachable
    
    --- 172.20.0.60 ping statistics ---
    1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms
    
    From cnetns1 to rootns and cnetns0 
    
    [root@rhel8b-cnetns1 ~ # ping -c 1 172.20.0.6
    PING 172.20.0.6 (172.20.0.6) 56(84) bytes of data.
    From 172.20.0.60 icmp_seq=1 Destination Host Unreachable
    
    --- 172.20.0.6 ping statistics ---
    1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms
    
    [root@rhel8b-cnetns1 ~ # ping -c 1 172.20.0.50
    PING 172.20.0.50 (172.20.0.50) 56(84) bytes of data.
    From 172.20.0.60 icmp_seq=1 Destination Host Unreachable
    
    --- 172.20.0.50 ping statistics ---
    1 packets transmitted, 0 received, +1 errors, 100% packet loss, time 0ms
    
    So the routes are good from rootns and cnetns0  because of which they are reachable but the pings from 
    cnetns1 resulted in   100% packet loss!
    

</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Static routes and precedence! </h3>
	<p> Why would centns0 fail to communicate between either of these namespaces and what are the things
        that can be looked at? So if we learn the routes that got configured on the rootns - they have two 
        static routes. </p>
	<p> </p>

<pre>


    [root@rhel8b ~]# ip route show
    default via 192.168.122.1 dev enp1s0 proto dhcp metric 100
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
    172.20.0.0/16 dev veth0 proto kernel scope link src 172.20.0.5
    172.20.0.0/16 dev veth1 proto kernel scope link src 172.20.0.6
    192.168.122.0/24 dev enp1s0 proto kernel scope link src 192.168.122.130 metric 100
    
    There are two static routes of interest here , this means any packet originating from the rootns heading 
    toward the subnet 172.20.0.0/16 will be going out of veth0  interface with an IP address of 172.20.0.5.
    
    172.20.0.0/16 dev veth0 proto kernel scope link src 172.20.0.5
    172.20.0.0/16 dev veth1 proto kernel scope link src 172.20.0.6
    
    Since 172.20.0.6 falls within the subnet range of 172.20.0.0/16 , packet gets routed through this interface
     hitting the cnetns0 and will reach back to the cnetns1.
    
    Additional way to solidify the theory is to look at the routing cache, which indicates the same that in 
    order to get to 172.20.0.60, the packet goes through the veth0.
    
    [root@rhel8b ~]# ip route get 172.20.0.60
    172.20.0.60 dev veth0 src 172.20.0.5 uid 0
        cache
    
    For additional reference, did tcpdumps on the cnetns0 interface while the ping was fired from the rootns 
    and there was ARP calls indicating the packet reached this interface but unable to find out where to route 
    the packets to.
    
    
    [root@rhel8b-cnetns0 ~ # tcpdump -nni ceth0 -vvv
    dropped privs to tcpdump
    tcpdump: listening on ceth0, link-type EN10MB (Ethernet), capture size 262144 bytes
    21:09:53.808981 ARP, Ethernet (len 6), IPv4 (len 4), Request who-has 172.20.0.60 tell 172.20.0.5, length 28
    
    </pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Configure the bridge. </h3>
	<p> The static routes were added when the interface was brought up with valid ip’s. So if one of these 
        routes were to be deleted, it will break the communication to the other network namespace!  It’s natural
         to have multiple network namespaces ( docker containers) running in one VM - so this is a valid use
          case that must work!

        172.20.0.0/16 dev veth0 proto kernel scope link src 172.20.0.5
        172.20.0.0/16 dev veth1 proto kernel scope link src 172.20.0.6 
        
        So the solution here is to create a bridge and attach the interfaces to it. Bridge acts on the L2 layer,
         this means it does the switching but not the routing but any interfaces using the bridge would have it’s 
         MAC address added and on the L2 layer the packets can be 
        
        
         </p>
	<p> </p>

<pre>

     
    Delete the IP addresses associated with the veth0 and veth1
    
    [root@rhel8b ~]# ip addr delete 172.20.0.5/16 dev veth0
    [root@rhel8b ~]# ip addr delete 172.20.0.6/16 dev veth1
    
    Flusing these out will also remove the routes that were added.
    
    [root@rhel8b ~]# ip route show
    default via 192.168.122.1 dev enp1s0 proto dhcp metric 100
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
    192.168.122.0/24 dev enp1s0 proto kernel scope link src 192.168.122.130 metric 100
    

    [root@rhel8b ~]# ip link add br00 type bridge
    [root@rhel8b ~]# ip link set br00 up
  
    [root@rhel8b ~]# ip link set veth0 master br00
    [root@rhel8b ~]# ip link set veth1 master br00
    
    [root@rhel8b ~]# ip link show br00
    8: br00: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
        link/ether 82:5c:78:97:0b:f4 brd ff:ff:ff:ff:ff:ff
    

    [root@rhel8b ~]# ip link show
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    2: enp1s0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP mode DEFAULT group default qlen 1000
        link/ether 52:54:00:01:1a:b3 brd ff:ff:ff:ff:ff:ff
    3: docker0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default
        link/ether 02:42:67:e9:9c:2a brd ff:ff:ff:ff:ff:ff
    5: veth0@if4: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br00 state UP mode DEFAULT group default qlen 1000
        link/ether 32:e4:7c:d5:bd:8f brd ff:ff:ff:ff:ff:ff link-netns cnetns0
    7: veth1@if6: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue master br00 state UP mode DEFAULT group default qlen 1000
        link/ether ea:c9:3d:5b:64:59 brd ff:ff:ff:ff:ff:ff link-netns cnetns1
    8: br00: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
        link/ether 32:e4:7c:d5:bd:8f brd ff:ff:ff:ff:ff:ff
    
    Checking the connectivity on the bridge level, the Mac addresses of both the interfaces are learned in each of these namespaces. 
    
    [root@rhel8b-cnetns0 ~ # ip neigh
    172.20.0.60 dev ceth0 lladdr f6:0e:f5:ee:d1:7e STALE
    
    [root@rhel8b-cnetns0 ~ # ip link show
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    4: ceth0@if5: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
        link/ether 3a:9c:07:b7:10:bd brd ff:ff:ff:ff:ff:ff link-netnsid 0
    
    [root@rhel8b-cnetns1 ~ # ip neigh
    172.20.0.50 dev ceth1 lladdr 3a:9c:07:b7:10:bd STALE
    
    [root@rhel8b-cnetns1 ~ # ip link show
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    6: ceth1@if7: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP mode DEFAULT group default qlen 1000
        link/ether f6:0e:f5:ee:d1:7e brd ff:ff:ff:ff:ff:ff link-netnsid 0
    
    
</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Ping tests failures between rootns/cnetns*  </h3>
	<p> At this point  since we have the bridge configured and MAC”s for each of these cethX interfaces are 
        learned by the bridge the L2 
        Layer packet forwarding should work and rootns should be able to reach cnetns0 and cnetns1 and also
         between the centns* interfaces there should be reachability as well. On the contrary  - none of them 
         are working.
        
        So I want to break this down into two issues
        
        a) Root NS cannot talk to cnetns*
        b) cnetns cannot talk to each other.
    </p>
	<p> </p>

<pre>
</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Why IP’s within cnetns are not reachable from root namespace? </h3>
	<p> Issue-1 : Root NS cannot to ceth0 and ceth1 on the child namespaces. Looking at the routes, any IP’s
         headed towards the subnet 172.17.0.0/16 will be going out of docker0 interface and any IP’s headed 
         towards 192.168.122.0/24  will be going out of enp1s0 interface and rest all should go via enp1s0 as 
         part of the default route “default via 192.168.122.1 dev enp1s0”.

        So this means a ping to 172.20.0.50 will never reach veth0 since it will be routed through the enp1s0 
        unless there’s a static route added here bound to the veth0 interface.
        </p>
	<p> </p>

<pre>

    [root@rhel8b ~]# ping -c1 172.20.0.50
    PING 172.20.0.50 (172.20.0.50) 56(84) bytes of data.
    
    --- 172.20.0.50 ping statistics ---
    1 packets transmitted, 0 received, 100% packet loss, time 0ms
    
    
    [root@rhel8b ~]# ip route show
    default via 192.168.122.1 dev enp1s0 proto dhcp metric 100
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
    192.168.122.0/24 dev enp1s0 proto kernel scope link src 192.168.122.130 metric 100
    
    Let me try a tcpdump to validate the theory (before the static route is added to see if the packets are 
    hitting the wire on the enp1s0 ).
    
    
    [root@rhel8b ~]# tcpdump -nni enp1s0 net 172.20.0.0/16
    dropped privs to tcpdump
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on enp1s0, link-type EN10MB (Ethernet), capture size 262144 bytes
    14:06:12.876136 IP 192.168.122.130 > 172.20.0.50: ICMP echo request, id 6820, seq 1, length 64
    
    So by adding a gateway IP address to the bridge, it should also plug in a static route in the routing table
     to ensure anything that should be routed for this network 172.20.0.0/16 should be going via br00 bridge 
     than the enp1s0. 
    
    
    
    [root@rhel8b ~]# ip addr show br00
    8: br00: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
        link/ether 32:e4:7c:d5:bd:8f brd ff:ff:ff:ff:ff:ff
        inet6 fe80::30e4:7cff:fed5:bd8f/64 scope link
           valid_lft forever preferred_lft forever
    [root@rhel8b ~]# ip addr add 172.20.0.1/16 dev br00
    [root@rhel8b ~]# ip addr show br00
    8: br00: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
        link/ether 32:e4:7c:d5:bd:8f brd ff:ff:ff:ff:ff:ff
        inet 172.20.0.1/16 scope global br00
           valid_lft forever preferred_lft forever
        inet6 fe80::30e4:7cff:fed5:bd8f/64 scope link
           valid_lft forever preferred_lft forever
    [root@rhel8b ~]# ip route show
    default via 192.168.122.1 dev enp1s0 proto dhcp metric 100
    172.17.0.0/16 dev docker0 proto kernel scope link src 172.17.0.1 linkdown
    172.20.0.0/16 dev br00 proto kernel scope link src 172.20.0.1
    192.168.122.0/24 dev enp1s0 proto kernel scope link src 192.168.122.130 metric 100
    
    
    Let’s try the pings again…
    
    [root@rhel8b ~]# ping -c1 172.20.0.50
    PING 172.20.0.50 (172.20.0.50) 56(84) bytes of data.
    64 bytes from 172.20.0.50: icmp_seq=1 ttl=64 time=0.089 ms
    
    --- 172.20.0.50 ping statistics ---
    1 packets transmitted, 1 received, 0% packet loss, time 0ms
    rtt min/avg/max/mdev = 0.089/0.089/0.089/0.000 ms
    
    So with the route in place , the rootns now can reach to the cnetns0 and cnetns1
    
    Issue still exists where the cnetns namespaces can’t talk to each other still..
     
    
</pre>		

</div>
<!-- container -->		


<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Why the IP’s between cnetns are not reachable between each other?  </h3>
	<p> This took me a while to figure out! So first the basics, whether the configuration is correct or not.

        So gateway/br00 is reachable yet the IP on cnetns1 is not reachable (172.20.0.60). I can see the 
        requests reaching the br00 (tcpdump) and also ceth1 (cnetns1) and it’s a ARP request and ARP response,
         yet it never reaches back.
        
        IP neigh output also stresses the fact that there’s no issue on the L2 layer, MAC’s on  br00 and as well 
        the respective interfaces - ceth0 and ceth1 are learned.
        
        This means bridge/L2 layer is completely in tact, yet  on the L3 there’s some issue! 
        </p>
	<p> </p>

<pre>


    [root@rhel8b-cnetns0 ~ # ping -c1 172.20.0.60
    PING 172.20.0.60 (172.20.0.60) 56(84) bytes of data.
    
    --- 172.20.0.60 ping statistics ---
    1 packets transmitted, 0 received, 100% packet loss, time 0ms
    
    [root@rhel8b-cnetns0 ~ # ping -c1 172.20.0.60
    PING 172.20.0.60 (172.20.0.60) 56(84) bytes of data.
    
    --- 172.20.0.60 ping statistics ---
    1 packets transmitted, 0 received, 100% packet loss, time 0ms
    
    
    [root@rhel8b ~]# tcpdump -nni br00 net 172.20.0.0/16
    dropped privs to tcpdump
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on br00, link-type EN10MB (Ethernet), capture size 262144 bytes
    14:53:33.614918 IP 172.20.0.50 > 172.20.0.60: ICMP echo request, id 6900, seq 1, length 64
    14:53:38.758399 ARP, Request who-has 172.20.0.60 tell 172.20.0.50, length 28
    14:53:38.758479 ARP, Reply 172.20.0.60 is-at f6:0e:f5:ee:d1:7e, length 28
    
    [root@rhel8b-cnetns1 ~ # tcpdump -nni ceth1 net 172.20.0.0/16
    dropped privs to tcpdump
    tcpdump: verbose output suppressed, use -v or -vv for full protocol decode
    listening on ceth1, link-type EN10MB (Ethernet), capture size 262144 bytes
    14:53:38.758447 ARP, Request who-has 172.20.0.60 tell 172.20.0.50, length 28
    14:53:38.758477 ARP, Reply 172.20.0.60 is-at f6:0e:f5:ee:d1:7e, length 28
    
    
    MAC Address’s learned by ceth0 and ceth1 
    
    [root@rhel8b-cnetns0 ~ # ip neigh
    172.20.0.60 dev ceth0 lladdr f6:0e:f5:ee:d1:7e STALE
    172.20.0.1 dev ceth0 lladdr 32:e4:7c:d5:bd:8f STALE
    
    [root@rhel8b-cnetns1 ~ # ip neigh
    172.20.0.1 dev ceth1 lladdr 32:e4:7c:d5:bd:8f STALE
    172.20.0.50 dev ceth1 lladdr 3a:9c:07:b7:10:bd STALE
    
Everything seems to be perfectly file on the L2 layer, so focus the investigation on the L3 layer!    
</pre>		

</div>
<!-- container -->		



<!-- container -->		
<div class="screen-one-item-container">
	<h3>  Issue-2: What's happening on L3, where/how are packets being dropped?  </h3>
	<p> This is the one where I spent most of the time. 
        Based on the ARP reply/response and as well the L2 checks being done, it’s clear that there’s some 
        issue on the L3 and that too on the rootns. One of the suspicion  is the IPTABLE rules/Firewall though I haven’t injected any explicit rules - all
         the VM’s that I carved out for experiments had docker daemon pre-configured for experimentation.
        
        Docker injects lot of rules, but unsure if that’s the one playing a rule here - so to find out more 
        I decided to review the rules.
        
        Lot’s of good articles on the IPTables, but need a recap of the same to understand how it’s working. 
        I picked one of this blog here (https://www.teldat.com/blog/nftables-and-netfilter-hooks-via-linux-kernel/) 
        “When a network packet is received on a network device, it first passes through the Prerouting hook. 
        This is where the routing decision takes place. The kernel decides whether the packet is destined for a local process (e.g., a listening socket on a server in this system) or whether to forward it (system operates as a router). In the first case, the packet passes the Input hook and is then handed over to the local process.  If the packet is destined to be forwarded, it traverses the Forward hook and then a final Postrouting hook before being sent out on a network device. For packets that are generated locally (e.g., by a client or server process that likes sending things out), they must first pass the Output hook and then the  Postrouting hook before being sent out on a network device.”
        
        
        So this means, I should definitely check the “FORWARDING” rule of the iptables, and probably the 
        “PRE-ROUTING” and “POST-ROUTING” as well! Later is not something I’m not too clear, but while doing
         the experiments I am hoping to get a better picture.
        
        The best of my understanding is I can focus only on the “FILTER” table, since I’m not using any natting , 
        NAT table shouldn’t come into play. Same for “MANGLE” as there’s nothing involved in modifying IP headers. RAW is used for connection tracking as per the documentation and SECURITY is for security purposes. SO I can now focus on the “FILTER”
        
        Within the “FILTER”, since it’s a packet that must be forwarded on the bridge from cnetns0 to cnetns1 
        (a packet destined to another interface ) on a separate namespace and it’s likely that if any of the 
        rules is affecting this it must be “FORWARD”.
        
         </p>
	<p> </p>

<pre>
    [root@rhel8b ~]#  iptables -t filter -L -n -v
    Chain INPUT (policy ACCEPT 32352 packets, 27M bytes)
     pkts bytes target     prot opt in     out     source               destination
    
    Chain FORWARD (policy DROP 15 packets, 1260 bytes)
     pkts bytes target     prot opt in     out     source               destination
       15  1260 DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0
       15  1260 DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0
        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0
        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0
        0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0
    
    Chain OUTPUT (policy ACCEPT 21299 packets, 1896K bytes)
     pkts bytes target     prot opt in     out     source               destination
    
    Chain DOCKER (1 references)
     pkts bytes target     prot opt in     out     source               destination
    
    Chain DOCKER-ISOLATION-STAGE-1 (1 references)
     pkts bytes target     prot opt in     out     source               destination
        0     0 DOCKER-ISOLATION-STAGE-2  all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0
       15  1260 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0
    
    Chain DOCKER-ISOLATION-STAGE-2 (1 references)
     pkts bytes target     prot opt in     out     source               destination
        0     0 DROP       all  --  *      docker0  0.0.0.0/0            0.0.0.0/0
        0     0 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0
    
    Chain DOCKER-USER (1 references)
     pkts bytes target     prot opt in     out     source               destination
       15  1260 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0
    
    
    If my interpretation is right, the default policy is “DROP”, drop any packets if no RULES are matched as listed! 
</pre>		

</div>
<!-- container -->		



<!-- container -->		
<div class="screen-one-item-container">
    <h3> Are packets getting dropped by iptables? Contd.   </h3>
    <p> So in-order for me to evaluate whether these rules are really affecting the packets, thought of taking a difference before and after the ping and look at the difference.
    </p>
    <img src="./img/iptables-diff-output.png" width="800" height="800"  alt="IPTables Output">   
						
	<p> </p>

<pre>


    [root@rhel8b ~]# iptables -L -v -n > /tmp/before_ping_from_cnetns0_to_cnetns1.dat

    [root@rhel8b-cnetns0 ~ # ping -c1 172.20.0.60
    PING 172.20.0.60 (172.20.0.60) 56(84) bytes of data.
    
    --- 172.20.0.60 ping statistics ---
    1 packets transmitted, 0 received, 100% packet loss, time 0ms
    
    [root@rhel8b ~]# iptables -L -v -n > /tmp/after_ping_from_cnetns0_to_cnetns1.dat
    
    
    [root@rhel8b ~]# diff --color /tmp/before_ping_from_cnetns0_to_cnetns1.dat /tmp/after_ping_from_cnetns0_to_cnetns1.dat
    1c1
    < Chain INPUT (policy ACCEPT 32513 packets, 27M bytes)
    ---
    > Chain INPUT (policy ACCEPT 32613 packets, 27M bytes)
    4c4
    < Chain FORWARD (policy DROP 16 packets, 1344 bytes)
    ---
    > Chain FORWARD (policy DROP 17 packets, 1428 bytes)
    6,7c6,7
    <    16  1344 DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    <    16  1344 DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    ---
    >    17  1428 DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    >    17  1428 DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    13c13
    < Chain OUTPUT (policy ACCEPT 21387 packets, 1914K bytes)
    ---
    > Chain OUTPUT (policy ACCEPT 21439 packets, 1920K bytes)
    22c22
    <    16  1344 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0
    ---
    >    17  1428 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0
    31c31
    <    16  1344 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0
    ---
    >    17  1428 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0
    
    
    What’s interesting here is there’s a packet that’s DROPPED in the “FORWARD” policy.
    
    < Chain FORWARD (policy DROP 16 packets, 1344 bytes)
    ---
    > Chain FORWARD (policy DROP 17 packets, 1428 bytes)
    
    
</pre>		

</div>
<!-- container -->		



<!-- container -->		
<div class="screen-one-item-container">
	<h3> IPTable Rules and Solution to packet drops! </h3>
	<p> I want to inject some logging to see the packets that are getting dropped as part of these rules. 
        So take a backup of the iptables and then add some additional rules to log all the packets getting 
        into this chain. So create a new chain called br00 and creating rules with a policy of "ACCEPT" for
         any packets that are destined to 172.20.0.0/16.

        So glad that I didn't delete/shutdown the docker daemon to have a cleaner system! This took me an entirely different
        and an interesting learning experience.
    </p>
	<p> </p>

<pre>

    iptables-save > /root/iptables.original

    iptables -N br00
    iptables -A br00 -m limit --limit 2/min -j LOG --log-prefix "DEBUG: Packets on wire - br00 " --log-level 4
    iptables -A br00  -j ACCEPT
    iptables -I FORWARD 1 -s 172.20.0.0/16 -o br00 -j br00
    iptables -I FORWARD 2 -s 172.20.0.0/16 -i br00 -j br00

    
    And let’s check if the LOGGING chain has been added
    
    
    [root@rhel8b ~]# iptables -L -v -n --line-numbers
    Chain INPUT (policy ACCEPT 68 packets, 5164 bytes)
    num   pkts bytes target     prot opt in     out     source               destination

    Chain FORWARD (policy DROP 1 packets, 84 bytes)
    num   pkts bytes target     prot opt in     out     source               destination
    1        0     0 br00       all  --  *      br00    172.20.0.0/16        0.0.0.0/0
    2        0     0 br00       all  --  br00   *       172.20.0.0/16        0.0.0.0/0
    3        1    84 DOCKER-USER  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    4        1    84 DOCKER-ISOLATION-STAGE-1  all  --  *      *       0.0.0.0/0            0.0.0.0/0
    5        0     0 ACCEPT     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0            ctstate RELATED,ESTABLISHED
    6        0     0 DOCKER     all  --  *      docker0  0.0.0.0/0            0.0.0.0/0
    7        0     0 ACCEPT     all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0
    8        0     0 ACCEPT     all  --  docker0 docker0  0.0.0.0/0            0.0.0.0/0

    Chain OUTPUT (policy ACCEPT 47 packets, 8140 bytes)
    num   pkts bytes target     prot opt in     out     source               destination

    Chain DOCKER (1 references)
    num   pkts bytes target     prot opt in     out     source               destination

    Chain DOCKER-ISOLATION-STAGE-1 (1 references)
    num   pkts bytes target     prot opt in     out     source               destination
    1        0     0 DOCKER-ISOLATION-STAGE-2  all  --  docker0 !docker0  0.0.0.0/0            0.0.0.0/0
    2        1    84 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0

    Chain DOCKER-ISOLATION-STAGE-2 (1 references)
    num   pkts bytes target     prot opt in     out     source               destination
    1        0     0 DROP       all  --  *      docker0  0.0.0.0/0            0.0.0.0/0
    2        0     0 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0

    Chain DOCKER-USER (1 references)
    num   pkts bytes target     prot opt in     out     source               destination
    1        1    84 RETURN     all  --  *      *       0.0.0.0/0            0.0.0.0/0

    Chain br00 (2 references)
    num   pkts bytes target     prot opt in     out     source               destination
    1        0     0 LOG        all  --  *      *       0.0.0.0/0            0.0.0.0/0            limit: avg 2/min burst 5 LOG flags 0 level 4 prefix "DEBUG: Packets on wire - br00"
    2        0     0 ACCEPT     all  --  *      *       0.0.0.0/0            0.0.0.0/0


        # Do a ping to see and see what get’s into the /var/log/messages ( the rules pushed by IPTABLES ) logging chain.
        
    [root@rhel8b-cnetns0 ~ # ping -c1 172.20.0.60
    PING 172.20.0.60 (172.20.0.60) 56(84) bytes of data.
    64 bytes from 172.20.0.60: icmp_seq=1 ttl=64 time=0.094 ms

    --- 172.20.0.60 ping statistics ---
    1 packets transmitted, 1 received, 0% packet loss, time 0ms
    rtt min/avg/max/mdev = 0.094/0.094/0.094/0.000 ms


    [root@rhel8b ~]# tail -2f /var/log/messages
    Dec 22 17:07:14 rhel8b systemd[1]: Started Network Manager Script Dispatcher Service.
    Dec 22 17:07:25 rhel8b systemd[1]: NetworkManager-dispatcher.service: Succeeded.
    Dec 22 17:16:10 rhel8b kernel: DEBUG: Packets on wire - br00IN=br00 OUT=br00 PHYSIN=veth0 PHYSOUT=veth1 MAC=f6:0e:f5:ee:d1:7e:3a:9c:07:b7:10:bd:08:00 SRC=172.20.0.50 DST=172.20.0.60 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=35184 DF PROTO=ICMP TYPE=8 CODE=0 ID=7316 SEQ=1
    Dec 22 17:16:10 rhel8b kernel: DEBUG: Packets on wire - br00IN=br00 OUT=br00 PHYSIN=veth1 PHYSOUT=veth0 MAC=3a:9c:07:b7:10:bd:f6:0e:f5:ee:d1:7e:08:00 SRC=172.20.0.60 DST=172.20.0.50 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=21476 PROTO=ICMP TYPE=0 CODE=0 ID=7316 SEQ=1


    [root@rhel8b-cnetns1 ~ # ping -c1 172.20.0.50
    PING 172.20.0.50 (172.20.0.50) 56(84) bytes of data.
    64 bytes from 172.20.0.50: icmp_seq=1 ttl=64 time=0.106 ms

    --- 172.20.0.50 ping statistics ---
    1 packets transmitted, 1 received, 0% packet loss, time 0ms
    rtt min/avg/max/mdev = 0.106/0.106/0.106/0.000 ms


    [root@rhel8b ~]# tail -2f /var/log/messages
    …output trimmed…
    ====
    Dec 22 17:17:21 rhel8b kernel: DEBUG: Packets on wire - br00IN=br00 OUT=br00 PHYSIN=veth1 PHYSOUT=veth0 MAC=3a:9c:07:b7:10:bd:f6:0e:f5:ee:d1:7e:08:00 SRC=172.20.0.60 DST=172.20.0.50 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=24247 DF PROTO=ICMP TYPE=8 CODE=0 ID=7317 SEQ=1
    Dec 22 17:17:21 rhel8b kernel: DEBUG: Packets on wire - br00IN=br00 OUT=br00 PHYSIN=veth0 PHYSOUT=veth1 MAC=f6:0e:f5:ee:d1:7e:3a:9c:07:b7:10:bd:08:00 SRC=172.20.0.50 DST=172.20.0.60 LEN=84 TOS=0x00 PREC=0x00 TTL=64 ID=12916 PROTO=ICMP TYPE=0 CODE=0 ID=7317 SEQ=1    



</pre>		

</div>
<!-- container -->		
 
  

	

</body>
</html>
